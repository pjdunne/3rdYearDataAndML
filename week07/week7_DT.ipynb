{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week X - Decision Trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "# Index: <a id='index'></a>\n",
    "1. [Introduction to Decision Trees](#classification)\n",
    "1. [Classification](#overfitting)\n",
    "1. [Regression](#regression)\n",
    "1. [Poor Predictors](#poor)\n",
    "1. [Ways to Improve Decision Trees](#rf)\n",
    "    1. [Bagging](#feature)\n",
    "    1. [Random Forests](#boosting)\n",
    "    1. [Gradient boosts](#appendix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keywords:** CART Algorithm, overfitting, ensembles, OOB score, bagging, pasting, random forests, "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Section One: Introduction to Decision Trees [^](#index) <a id='classification'></a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees (DTs) are a versatile machine learning algorithm that can perform both classification and regression tasks. They are very powerful algorithms, capable of fitting complex datasets. \n",
    "\n",
    "They are fundamental components of **random forests** (see later), which are among the most powerful machine learning algorithms available today. 'A forest is a set of trees', as we will see later. The intuition behind a decision tree is to partiion the space of predictors and classifty according to the splits. \n",
    "\n",
    "Briefly, a decision tree will successively split the input space into regions. This can be visualised as a binary tree: Each region is assigned a node, also known as **leaf nodes**. At any depth of the tree, the leaf nodes correspond to regions whose union gives us the *full input space*. The key insight is to find the splits for the regions that will separate samples of different classes into different regions, while keeping samples of the same class in the\n",
    "same region (as much as possible).\n",
    "\n",
    "The setup is the usual:\n",
    "\\begin{equation*}\n",
    "\\textbf{X}=(X_{1},X_{2},...,X_{N}) \\rightarrow y\n",
    "\\end{equation*}\n",
    "The input and output data can be discrete or continuous. This is why decision trees can be used for both classification and regression. \n",
    "\n",
    "**Note:** DTs have been generalised to multivariate outputs however for this course we will restrict ourselves to a problem with a single output varaible. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Section Two: Classification Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an unseen sample $X^{\\text{in}}$, with $N$ descriptors, our objective is to predict its class $y \\in \\mathcal{C}_{N}=\\{c_{1},...,c_{N}\\}$. \n",
    "\n",
    "Each split can be thought of as a *decision* that generates a *tree*. The split is limited to one input variable at a time and can be defined by a pair $(j,s)$, where $j$ is the input variable used for the decision and $s$ is the threshold chosen. \n",
    "\n",
    "This is best shown visually for two input variables and then a more formal definition can be given:\n",
    "\n",
    "\n",
    "<td><img src=week07_photos/DT_basic_example.png align='center' height=400/></td>\n",
    "\n",
    "*Placeholder image* \n",
    "\\begin{equation*}\n",
    "\n",
    "\\end{equation*}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Section Three: Regression Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Section Four: Limits of Decision Trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Section Five: Improving Decision Trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
